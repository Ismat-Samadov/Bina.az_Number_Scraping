{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32e5f707-48a0-44bb-a556-85c6f2371e20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70180166-a0ee-4bc5-902d-43ba6bf8d8d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fa96efe-ee20-4fb3-b43d-5226eef21374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 188 ms\n",
      "Wall time: 5.65 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import scrapy as sc\n",
    "import requests\n",
    "import re \n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "links=[]\n",
    "numbers=[]\n",
    "for pages in range(1,3):\n",
    "    url=f'https://bina.az/alqi-satqi?page={pages}'\n",
    "    request=requests.get(url).content\n",
    "    soup=BeautifulSoup(request,'html.parser')\n",
    "    content=soup.find_all('div',class_='items-i')\n",
    "    time.sleep(2)\n",
    "    for i in range(len(content)):\n",
    "        links.append('https://bina.az'+content[i].a['href'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b99dbd3f-129d-4b6f-a047-2c57b2087900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 172 ms\n",
      "Wall time: 5.29 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "links = []\n",
    "numbers = []\n",
    "\n",
    "for page in range(1, 3):\n",
    "    url = f'https://bina.az/alqi-satqi?page={page}'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    content = soup.find_all('div', class_='items-i')\n",
    "    time.sleep(2)\n",
    "    \n",
    "    for item in content:\n",
    "        link = 'https://bina.az' + item.a['href']\n",
    "        links.append(link)\n",
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3f2d73e-4249-4d49-a67a-377de1ede7fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Create DataFrame\u001b[39;00m\n\u001b[0;32m     30\u001b[0m data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlink\u001b[39m\u001b[38;5;124m'\u001b[39m: links, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumbers\u001b[39m\u001b[38;5;124m'\u001b[39m: numbers}\n\u001b[1;32m---> 31\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Display the DataFrame\u001b[39;00m\n\u001b[0;32m     34\u001b[0m df\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:664\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    658\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    659\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    660\u001b[0m     )\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 664\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    666\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    490\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    491\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:118\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:666\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    664\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 666\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    669\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    670\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    671\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "links = []\n",
    "numbers = []\n",
    "\n",
    "for page in range(1, 3):\n",
    "    url = f'https://bina.az/alqi-satqi?page={page}'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    content = soup.find_all('div', class_='items-i')\n",
    "    time.sleep(2)\n",
    "    \n",
    "    for item in content:\n",
    "        link = 'https://bina.az' + item.a['href']\n",
    "        links.append(link)\n",
    "        \n",
    "        # Extract phone numbers from the link\n",
    "        link_response = requests.get(link)\n",
    "        link_soup = BeautifulSoup(link_response.content, 'html.parser')\n",
    "        phone_numbers = link_soup.find_all('div', class_='product-phones__list-i')\n",
    "        \n",
    "        # Store phone numbers\n",
    "        for number in phone_numbers:\n",
    "            numbers.append(number.text.strip())\n",
    "            \n",
    "# Create DataFrame\n",
    "data = {'link': links, 'numbers': numbers}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25180735-2716-4636-ad3e-b049790a13c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: The number of links and phone numbers are not equal.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "links = []\n",
    "numbers = []\n",
    "\n",
    "for page in range(1, 3):\n",
    "    url = f'https://bina.az/alqi-satqi?page={page}'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    content = soup.find_all('div', class_='items-i')\n",
    "    time.sleep(2)\n",
    "    \n",
    "    for item in content:\n",
    "        link = 'https://bina.az' + item.a['href']\n",
    "        links.append(link)\n",
    "        \n",
    "        # Extract phone numbers from the link\n",
    "        link_response = requests.get(link)\n",
    "        link_soup = BeautifulSoup(link_response.content, 'html.parser')\n",
    "        phone_numbers = link_soup.find_all('div', class_='product-phones__list-i')\n",
    "        \n",
    "        # Store phone numbers\n",
    "        for number in phone_numbers:\n",
    "            numbers.append(number.text.strip())\n",
    "            \n",
    "# Check if the number of links and phone numbers are equal\n",
    "if len(links) == len(numbers):\n",
    "    # Create DataFrame\n",
    "    data = {'link': links, 'numbers': numbers}\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Display the DataFrame\n",
    "    print(df)\n",
    "else:\n",
    "    print(\"Error: The number of links and phone numbers are not equal.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7d1f73b-9930-4bf8-97cc-bc929efb430f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "data = []\n",
    "\n",
    "for page in range(1, 2):\n",
    "    url = f'https://bina.az/alqi-satqi?page={page}'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    content = soup.find_all('div', class_='items-i')\n",
    "    time.sleep(2)\n",
    "    \n",
    "    for item in content:\n",
    "        link = 'https://bina.az' + item.a['href']\n",
    "        \n",
    "        # Extract phone numbers from the link\n",
    "        link_response = requests.get(link)\n",
    "        link_soup = BeautifulSoup(link_response.content, 'html.parser')\n",
    "        phone_numbers = link_soup.find_all('div', class_='product-phones__list-i')\n",
    "        \n",
    "        # Store each phone number as a separate row\n",
    "        for number in phone_numbers:\n",
    "            data.append({'link': link, 'number': number.text.strip()})\n",
    "            \n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0563e1f-0a7c-4740-8792-bef8aaefe4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "data = []\n",
    "\n",
    "for page in range(1, 3):\n",
    "    url = f'https://bina.az/alqi-satqi?page={page}'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    content = soup.find_all('div', class_='items-i')\n",
    "    time.sleep(2)\n",
    "    \n",
    "    for item in content:\n",
    "        link = 'https://bina.az' + item.a['href']\n",
    "        \n",
    "        # Extract phone numbers from the link\n",
    "        link_response = requests.get(link)\n",
    "        link_soup = BeautifulSoup(link_response.content, 'html.parser')\n",
    "        phone_numbers = link_soup.find_all('div', class_='product-phones__list-i')\n",
    "        \n",
    "        # Store each phone number as a separate row\n",
    "        for number in phone_numbers:\n",
    "            data.append({'link': link, 'number': number.text.strip()})\n",
    "            \n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "725eeba7-7b34-4b99-8117-ebc4e7c36ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')  # Run Chrome WebDriver in headless mode\n",
    "driver = webdriver.Chrome(options=chrome_options)  # Assuming you have Chrome WebDriver installed\n",
    "\n",
    "data = []\n",
    "\n",
    "for page in range(1, 3):\n",
    "    url = f'https://bina.az/alqi-satqi?page={page}'\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    content = soup.find_all('div', class_='items-i')\n",
    "    \n",
    "    for item in content:\n",
    "        link = 'https://bina.az' + item.a['href']\n",
    "        \n",
    "        driver.get(link)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        link_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        button = link_soup.find('button', text='Nömrəni göstər')\n",
    "        \n",
    "        if button:\n",
    "            button.click()\n",
    "            time.sleep(1)\n",
    "            \n",
    "            updated_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            phone_numbers = updated_soup.find_all('div', class_='product-phones__list-i')\n",
    "            \n",
    "            if phone_numbers:\n",
    "                for number in phone_numbers:\n",
    "                    data.append({'link': link, 'number': number.text.strip()})\n",
    "            else:\n",
    "                data.append({'link': link, 'number': None})\n",
    "        \n",
    "driver.quit()\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca014a8b-e70c-4b19-b1f7-9709bff86d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')  # Run Chrome WebDriver in headless mode\n",
    "driver = webdriver.Chrome(options=chrome_options)  # Assuming you have Chrome WebDriver installed\n",
    "\n",
    "data = []\n",
    "\n",
    "for page in range(1, 3):\n",
    "    url = f'https://bina.az/alqi-satqi?page={page}'\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    content = soup.find_all('div', class_='items-i')\n",
    "    \n",
    "    for item in content:\n",
    "        link = 'https://bina.az' + item.a['href']\n",
    "        \n",
    "        driver.get(link)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        link_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        button = link_soup.find('button', text='Nömrəni göstər')\n",
    "        \n",
    "        if button:\n",
    "            button.click()\n",
    "            time.sleep(1)\n",
    "            \n",
    "            updated_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            phone_number_link = updated_soup.find('a', href=re.compile('^tel:'))\n",
    "            \n",
    "            if phone_number_link:\n",
    "                phone_number = phone_number_link['href'][4:]  # Extract the phone number from the href attribute\n",
    "                data.append({'link': link, 'number': phone_number})\n",
    "            else:\n",
    "                data.append({'link': link, 'number': None})\n",
    "        \n",
    "driver.quit()\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0419dec7-e15e-4ba0-a594-80ddeca476c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')  # Run Chrome WebDriver in headless mode\n",
    "driver = webdriver.Chrome(options=chrome_options)  # Assuming you have Chrome WebDriver installed\n",
    "\n",
    "data = []\n",
    "\n",
    "for page in range(1, 3):\n",
    "    url = f'https://bina.az/alqi-satqi?page={page}'\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    content = soup.find_all('div', class_='items-i')\n",
    "    \n",
    "    for item in content:\n",
    "        link = 'https://bina.az' + item.a['href']\n",
    "        \n",
    "        driver.get(link)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        link_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        button = link_soup.find('button', text='Nömrəni göstər')\n",
    "        \n",
    "        if button:\n",
    "            button.click()\n",
    "            time.sleep(1)\n",
    "            \n",
    "            updated_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            phone_number_link = updated_soup.find('a', href=re.compile('^tel:'))\n",
    "            \n",
    "            if phone_number_link:\n",
    "                phone_number = phone_number_link.text.strip()  # Extract the phone number from the link text\n",
    "                data.append({'link': link, 'number': phone_number})\n",
    "            else:\n",
    "                data.append({'link': link, 'number': None})\n",
    "        \n",
    "driver.quit()\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "378d661a-4867-4578-be24-7187369d4d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')  # Run Chrome WebDriver in headless mode\n",
    "driver = webdriver.Chrome(options=chrome_options)  # Assuming you have Chrome WebDriver installed\n",
    "\n",
    "data = []\n",
    "\n",
    "for page in range(1, 2):\n",
    "    url = f'https://bina.az/alqi-satqi?page={page}'\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    content = soup.find_all('div', class_='items-i')\n",
    "    \n",
    "    for item in content:\n",
    "        link = 'https://bina.az' + item.a['href']\n",
    "        \n",
    "        driver.get(link)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        link_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        button = link_soup.find('button', text='Nömrəni göstər')\n",
    "        \n",
    "        if button:\n",
    "            button.click()\n",
    "            time.sleep(1)\n",
    "            \n",
    "            updated_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            phone_number_links = updated_soup.find_all('a', href=re.compile('^tel:'))\n",
    "            \n",
    "            if phone_number_links:\n",
    "                numbers = [link.text.strip() for link in phone_number_links]\n",
    "                data.extend({'link': link, 'number': number} for number in numbers)\n",
    "            else:\n",
    "                data.append({'link': link, 'number': None})\n",
    "        \n",
    "driver.quit()\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00806c48-29bd-48a2-bee5-16295050f32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')  # Run Chrome WebDriver in headless mode\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "data = []\n",
    "\n",
    "for page in range(1, 3):\n",
    "    url = f'https://bina.az/alqi-satqi?page={page}'\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    content = soup.find_all('div', class_='items-i')\n",
    "\n",
    "    for item in content:\n",
    "        link = 'https://bina.az' + item.a['href']\n",
    "\n",
    "        driver.get(link)\n",
    "        time.sleep(2)\n",
    "\n",
    "        link_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        button = link_soup.find('button', text='Nömrəni göstər')\n",
    "\n",
    "        if button:\n",
    "            button.click()\n",
    "            time.sleep(1)\n",
    "\n",
    "            updated_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            phone_number_links = updated_soup.find_all('a', href=re.compile('^tel:'))\n",
    "\n",
    "            if phone_number_links:\n",
    "                numbers = [link['href'][4:] for link in phone_number_links]\n",
    "                data.extend({'link': link, 'number': number} for number in numbers)\n",
    "            else:\n",
    "                data.append({'link': link, 'number': None})\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8defda72-8d68-4dd9-8dc5-f90d0618d408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')  # Run Chrome WebDriver in headless mode\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "data = []\n",
    "\n",
    "for page in range(1, 3):\n",
    "    url = f'https://bina.az/alqi-satqi?page={page}'\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    content = soup.find_all('div', class_='items-i')\n",
    "\n",
    "    for item in content:\n",
    "        link = 'https://bina.az' + item.a['href']\n",
    "\n",
    "        driver.get(link)\n",
    "        time.sleep(2)\n",
    "\n",
    "        link_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        button = link_soup.find('button', text='Nömrəni göstər')\n",
    "\n",
    "        if button:\n",
    "            button.click()\n",
    "            time.sleep(1)\n",
    "\n",
    "            updated_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            phone_number_links = updated_soup.find_all('a', href=re.compile('^tel:'))\n",
    "\n",
    "            if phone_number_links:\n",
    "                numbers = [link['href'][4:] for link in phone_number_links]\n",
    "                data.append({'link': link, 'numbers': numbers})\n",
    "            else:\n",
    "                data.append({'link': link, 'numbers': None})\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75a1e1c2-fee1-4df9-9bca-605f684f6f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')  # Run Chrome WebDriver in headless mode\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "data = []\n",
    "\n",
    "for page in range(1, 3):\n",
    "    url = f'https://bina.az/alqi-satqi?page={page}'\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    content = soup.find_all('div', class_='items-i')\n",
    "\n",
    "    for item in content:\n",
    "        link = 'https://bina.az' + item.a['href']\n",
    "\n",
    "        driver.get(link)\n",
    "        time.sleep(2)\n",
    "\n",
    "        link_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        button = link_soup.find('button', text='Nömrəni göstər')\n",
    "\n",
    "        if button:\n",
    "            button.click()\n",
    "            time.sleep(1)\n",
    "\n",
    "            updated_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            phone_number_links = updated_soup.find_all('a', href=re.compile('^tel:'))\n",
    "\n",
    "            if phone_number_links:\n",
    "                numbers = [link['href'][4:] for link in phone_number_links]\n",
    "                for number in numbers:\n",
    "                    data.append({'link': link, 'number': number})\n",
    "            else:\n",
    "                data.append({'link': link, 'number': None})\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d845d17-9b4a-480e-833d-e6e0e828a2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')  # Run Chrome WebDriver in headless mode\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "data = []\n",
    "\n",
    "for page in range(1, 3):\n",
    "    url = f'https://bina.az/alqi-satqi?page={page}'\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    content = soup.find_all('div', class_='items-i')\n",
    "\n",
    "    for item in content:\n",
    "        link = 'https://bina.az' + item.a['href']\n",
    "\n",
    "        driver.get(link)\n",
    "        time.sleep(2)\n",
    "\n",
    "        link_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        button_div = link_soup.find('div', class_='product-phones__btn-title')\n",
    "        button = button_div.find_parent('button')\n",
    "\n",
    "        if button:\n",
    "            button.click()\n",
    "            time.sleep(1)\n",
    "\n",
    "            updated_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            phone_number_links = updated_soup.find_all('a', href=re.compile('^tel:'))\n",
    "\n",
    "            if phone_number_links:\n",
    "                numbers = [link['href'][4:] for link in phone_number_links]\n",
    "                for number in numbers:\n",
    "                    data.append({'link': link, 'number': number})\n",
    "            else:\n",
    "                data.append({'link': link, 'number': None})\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a2e8c988-d262-404f-980d-a4df1730bdd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "data = []\n",
    "\n",
    "for page in range(1, 3):\n",
    "    url = f'https://bina.az/alqi-satqi?page={page}'\n",
    "    response = requests.get(url)\n",
    "    time.sleep(2)\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    content = soup.find_all('div', class_='items-i')\n",
    "\n",
    "    for item in content:\n",
    "        link = 'https://bina.az' + item.a['href']\n",
    "        response = requests.get(link)\n",
    "        time.sleep(2)\n",
    "\n",
    "        link_soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        button_div = link_soup.find('div', class_='product-phones__btn-title')\n",
    "        button = button_div.find_parent('button')\n",
    "\n",
    "        if button:\n",
    "            response = requests.get(link + '?phone=1')\n",
    "            updated_soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            phone_number_links = updated_soup.find_all('a', href=re.compile('^tel:'))\n",
    "\n",
    "            if phone_number_links:\n",
    "                numbers = [link['href'][4:] for link in phone_number_links]\n",
    "                for number in numbers:\n",
    "                    data.append({'link': link, 'number': number})\n",
    "            else:\n",
    "                data.append({'link': link, 'number': None})\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f3f04a3f-b4ce-4f70-b992-9d8625a14ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             link           number\n",
      "0   https://bina.az/items/3521794  (055) 220-67-●●\n",
      "1   https://bina.az/items/3600640  (055) 210-11-●●\n",
      "2   https://bina.az/items/3600639  (055) 508-81-●●\n",
      "3   https://bina.az/items/3600637  (070) 611-51-●●\n",
      "4   https://bina.az/items/3599176  (050) 784-65-●●\n",
      "5   https://bina.az/items/3600635  (050) 228-30-●●\n",
      "6   https://bina.az/items/3600634  (050) 555-49-●●\n",
      "7   https://bina.az/items/3564700  (070) 371-11-●●\n",
      "8   https://bina.az/items/3600632  (070) 222-75-●●\n",
      "9   https://bina.az/items/3600631  (070) 219-99-●●\n",
      "10  https://bina.az/items/3600630  (055) 560-35-●●\n",
      "11  https://bina.az/items/3600629  (051) 270-33-●●\n",
      "12  https://bina.az/items/3600627  (055) 335-41-●●\n",
      "13  https://bina.az/items/3504922  (070) 578-05-●●\n",
      "14  https://bina.az/items/3422284  (070) 578-05-●●\n",
      "15  https://bina.az/items/3584989  (077) 568-00-●●\n",
      "16  https://bina.az/items/3592522  (077) 568-00-●●\n",
      "17  https://bina.az/items/3564910  (070) 804-57-●●\n",
      "18  https://bina.az/items/3600624  (070) 688-19-●●\n",
      "19  https://bina.az/items/3600622  (050) 660-15-●●\n",
      "20  https://bina.az/items/3585498  (099) 308-89-●●\n",
      "21  https://bina.az/items/3600620  (055) 518-99-●●\n",
      "22  https://bina.az/items/3600619  (050) 800-09-●●\n",
      "23  https://bina.az/items/3600618  (051) 596-09-●●\n",
      "24  https://bina.az/items/3600624  (070) 688-19-●●\n",
      "25  https://bina.az/items/3600622  (050) 660-15-●●\n",
      "26  https://bina.az/items/3585498  (099) 308-89-●●\n",
      "27  https://bina.az/items/3600620  (055) 518-99-●●\n",
      "28  https://bina.az/items/3600619  (050) 800-09-●●\n",
      "29  https://bina.az/items/3600618  (051) 596-09-●●\n",
      "30  https://bina.az/items/3570608  (070) 887-61-●●\n",
      "31  https://bina.az/items/3600617  (050) 209-36-●●\n",
      "32  https://bina.az/items/3536392  (050) 300-97-●●\n",
      "33  https://bina.az/items/3416612  (055) 507-49-●●\n",
      "34  https://bina.az/items/3600616  (077) 604-10-●●\n",
      "35  https://bina.az/items/3450481  (050) 290-61-●●\n",
      "36  https://bina.az/items/3450409  (050) 290-61-●●\n",
      "37  https://bina.az/items/3560241  (050) 289-27-●●\n",
      "38  https://bina.az/items/3600614  (070) 839-82-●●\n",
      "39  https://bina.az/items/3577146  (050) 290-61-●●\n",
      "40  https://bina.az/items/3600613  (051) 280-13-●●\n",
      "41  https://bina.az/items/3576999  (050) 290-61-●●\n",
      "42  https://bina.az/items/3595690  (055) 700-00-●●\n",
      "43  https://bina.az/items/3600611  (070) 611-51-●●\n",
      "44  https://bina.az/items/3600610  (050) 224-36-●●\n",
      "45  https://bina.az/items/3596915  (050) 211-89-●●\n",
      "46  https://bina.az/items/3488202  (070) 222-59-●●\n",
      "47  https://bina.az/items/3585133  (070) 222-59-●●\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "data = []\n",
    "\n",
    "for page in range(1, 3):\n",
    "    url = f'https://bina.az/alqi-satqi?page={page}'\n",
    "    response = requests.get(url)\n",
    "    time.sleep(2)\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    content = soup.find_all('div', class_='items-i')\n",
    "\n",
    "    for item in content:\n",
    "        link = 'https://bina.az' + item.a['href']\n",
    "        response = requests.get(link)\n",
    "        time.sleep(2)\n",
    "\n",
    "        link_soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        phone_div = link_soup.find('div', class_='product-phones__btn-value')\n",
    "\n",
    "        if phone_div:\n",
    "            phone_number = phone_div.text.strip()\n",
    "            data.append({'link': link, 'number': phone_number})\n",
    "        else:\n",
    "            data.append({'link': link, 'number': None})\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "420faccb-c28e-4bdb-9209-a1b465c86679",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m button_div \u001b[38;5;129;01mand\u001b[39;00m button_div\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNömrəni göstər\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     32\u001b[0m     button \u001b[38;5;241m=\u001b[39m button_div\u001b[38;5;241m.\u001b[39mfind_parent(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjs-show-phones product-phones__btn\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m     \u001b[43mbutton\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclick\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     36\u001b[0m     updated_soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(driver\u001b[38;5;241m.\u001b[39mpage_source, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')  # Run Chrome WebDriver in headless mode\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "data = []\n",
    "\n",
    "for page in range(1, 3):\n",
    "    url = f'https://bina.az/alqi-satqi?page={page}'\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    content = soup.find_all('div', class_='items-i')\n",
    "\n",
    "    for item in content:\n",
    "        link = 'https://bina.az' + item.a['href']\n",
    "\n",
    "        driver.get(link)\n",
    "        time.sleep(2)\n",
    "\n",
    "        link_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        button_div = link_soup.find('div', class_='product-phones__btn-title')\n",
    "\n",
    "        if button_div and button_div.text == 'Nömrəni göstər':\n",
    "            button = button_div.find_parent('div', class_='js-show-phones product-phones__btn')\n",
    "            button.click()\n",
    "            time.sleep(1)\n",
    "\n",
    "            updated_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            phone_div = updated_soup.find('div', class_='product-phones__btn-value')\n",
    "\n",
    "            if phone_div:\n",
    "                phone_number = phone_div.text.strip()\n",
    "                data.append({'link': link, 'number': phone_number})\n",
    "            else:\n",
    "                data.append({'link': link, 'number': None})\n",
    "        else:\n",
    "            data.append({'link': link, 'number': None})\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e475a937-ecb3-42d2-89bc-ebbec911e697",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m button_div \u001b[38;5;129;01mand\u001b[39;00m button_div\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNömrəni göstər\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     32\u001b[0m     button \u001b[38;5;241m=\u001b[39m button_div\u001b[38;5;241m.\u001b[39mfind_parent(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjs-show-phones product-phones__btn\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m---> 33\u001b[0m     \u001b[43mbutton\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclick\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     36\u001b[0m     updated_soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(driver\u001b[38;5;241m.\u001b[39mpage_source, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')  # Run Chrome WebDriver in headless mode\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "data = []\n",
    "\n",
    "for page in range(1, 3):\n",
    "    url = f'https://bina.az/alqi-satqi?page={page}'\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    content = soup.find_all('div', class_='items-i')\n",
    "\n",
    "    for item in content:\n",
    "        link = 'https://bina.az' + item.a['href']\n",
    "\n",
    "        driver.get(link)\n",
    "        time.sleep(2)\n",
    "\n",
    "        link_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        button_div = link_soup.find('div', class_='product-phones__btn-title')\n",
    "\n",
    "        if button_div and button_div.text == 'Nömrəni göstər':\n",
    "            button = button_div.find_parent('div', {'class': 'js-show-phones product-phones__btn'})\n",
    "            button.click()\n",
    "            time.sleep(1)\n",
    "\n",
    "            updated_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            phone_div = updated_soup.find('div', class_='product-phones__btn-value')\n",
    "\n",
    "            if phone_div:\n",
    "                phone_number = phone_div.text.strip()\n",
    "                data.append({'link': link, 'number': phone_number})\n",
    "            else:\n",
    "                data.append({'link': link, 'number': None})\n",
    "        else:\n",
    "            data.append({'link': link, 'number': None})\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d24c1fb-a11c-4c86-9177-b766d8afa85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  link           number\n",
      "0        https://bina.az/items/3600643  (055) 271-40-●●\n",
      "1        https://bina.az/items/3548872  (050) 228-34-●●\n",
      "2        https://bina.az/items/3447198  (055) 644-77-●●\n",
      "3        https://bina.az/items/3569248  (055) 644-77-●●\n",
      "4   https://bina.az/items/3499546.html  (055) 644-77-●●\n",
      "5        https://bina.az/items/3485011  (055) 644-77-●●\n",
      "6        https://bina.az/items/3569352  (055) 644-77-●●\n",
      "7        https://bina.az/items/3499602  (055) 644-77-●●\n",
      "8        https://bina.az/items/3521794  (055) 220-67-●●\n",
      "9        https://bina.az/items/3600640  (055) 210-11-●●\n",
      "10       https://bina.az/items/3600639  (055) 508-81-●●\n",
      "11       https://bina.az/items/3600637  (070) 611-51-●●\n",
      "12       https://bina.az/items/3599176  (050) 784-65-●●\n",
      "13       https://bina.az/items/3600635  (050) 228-30-●●\n",
      "14       https://bina.az/items/3600634  (050) 555-49-●●\n",
      "15       https://bina.az/items/3564700  (070) 371-11-●●\n",
      "16       https://bina.az/items/3600632  (070) 222-75-●●\n",
      "17       https://bina.az/items/3600631  (070) 219-99-●●\n",
      "18       https://bina.az/items/3600630  (055) 560-35-●●\n",
      "19       https://bina.az/items/3600629  (051) 270-33-●●\n",
      "20       https://bina.az/items/3600627  (055) 335-41-●●\n",
      "21       https://bina.az/items/3504922  (070) 578-05-●●\n",
      "22       https://bina.az/items/3422284  (070) 578-05-●●\n",
      "23       https://bina.az/items/3584989  (077) 568-00-●●\n",
      "24       https://bina.az/items/3504922  (070) 578-05-●●\n",
      "25       https://bina.az/items/3422284  (070) 578-05-●●\n",
      "26       https://bina.az/items/3584989  (077) 568-00-●●\n",
      "27       https://bina.az/items/3592522  (077) 568-00-●●\n",
      "28       https://bina.az/items/3564910  (070) 804-57-●●\n",
      "29       https://bina.az/items/3600624  (070) 688-19-●●\n",
      "30       https://bina.az/items/3600622  (050) 660-15-●●\n",
      "31       https://bina.az/items/3585498  (099) 308-89-●●\n",
      "32       https://bina.az/items/3600620  (055) 518-99-●●\n",
      "33       https://bina.az/items/3600619  (050) 800-09-●●\n",
      "34       https://bina.az/items/3600618  (051) 596-09-●●\n",
      "35       https://bina.az/items/3570608  (070) 887-61-●●\n",
      "36       https://bina.az/items/3600617  (050) 209-36-●●\n",
      "37       https://bina.az/items/3536392  (050) 300-97-●●\n",
      "38       https://bina.az/items/3416612  (055) 507-49-●●\n",
      "39       https://bina.az/items/3600616  (077) 604-10-●●\n",
      "40       https://bina.az/items/3450481  (050) 290-61-●●\n",
      "41       https://bina.az/items/3450409  (050) 290-61-●●\n",
      "42       https://bina.az/items/3560241  (050) 289-27-●●\n",
      "43       https://bina.az/items/3600614  (070) 839-82-●●\n",
      "44       https://bina.az/items/3577146  (050) 290-61-●●\n",
      "45       https://bina.az/items/3600613  (051) 280-13-●●\n",
      "46       https://bina.az/items/3576999  (050) 290-61-●●\n",
      "47       https://bina.az/items/3595690  (055) 700-00-●●\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')  # Run Chrome WebDriver in headless mode\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "data = []\n",
    "\n",
    "for page in range(1, 3):\n",
    "    url = f'https://bina.az/alqi-satqi?page={page}'\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    content = soup.find_all('div', class_='items-i')\n",
    "\n",
    "    for item in content:\n",
    "        link = 'https://bina.az' + item.a['href']\n",
    "\n",
    "        driver.get(link)\n",
    "        time.sleep(2)\n",
    "\n",
    "        link_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        button_div = link_soup.find('div', class_='product-phones__btn-title')\n",
    "\n",
    "        if button_div and button_div.text == 'Nömrəni göstər':\n",
    "            button_parent = button_div.find_parent('div', {'class': 'js-show-phones product-phones__btn'})\n",
    "            button_value = button_parent.find('div', class_='product-phones__btn-value')\n",
    "            if button_value:\n",
    "                phone_number = button_value.text.strip()\n",
    "                data.append({'link': link, 'number': phone_number})\n",
    "            else:\n",
    "                button_parent.click()\n",
    "                time.sleep(1)\n",
    "                updated_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                phone_div = updated_soup.find('div', class_='product-phones__btn-value')\n",
    "                if phone_div:\n",
    "                    phone_number = phone_div.text.strip()\n",
    "                    data.append({'link': link, 'number': phone_number})\n",
    "                else:\n",
    "                    data.append({'link': link, 'number': None})\n",
    "        else:\n",
    "            data.append({'link': link, 'number': None})\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6fc31131-fa62-4c71-8b0f-a14c6ce62bc3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'value'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 35\u001b[0m\n\u001b[0;32m     33\u001b[0m button_value \u001b[38;5;241m=\u001b[39m button_parent\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct-phones__btn-value\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m button_value:\n\u001b[1;32m---> 35\u001b[0m     phone_number \u001b[38;5;241m=\u001b[39m \u001b[43mbutton_value\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     36\u001b[0m     data\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlink\u001b[39m\u001b[38;5;124m'\u001b[39m: link, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumber\u001b[39m\u001b[38;5;124m'\u001b[39m: phone_number})\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\bs4\\element.py:1519\u001b[0m, in \u001b[0;36mTag.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m   1517\u001b[0m     \u001b[38;5;124;03m\"\"\"tag[key] returns the value of the 'key' attribute for the Tag,\u001b[39;00m\n\u001b[0;32m   1518\u001b[0m \u001b[38;5;124;03m    and throws an exception if it's not there.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'value'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')  # Run Chrome WebDriver in headless mode\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "data = []\n",
    "\n",
    "for page in range(1, 3):\n",
    "    url = f'https://bina.az/alqi-satqi?page={page}'\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    content = soup.find_all('div', class_='items-i')\n",
    "\n",
    "    for item in content:\n",
    "        link = 'https://bina.az' + item.a['href']\n",
    "\n",
    "        driver.get(link)\n",
    "        time.sleep(2)\n",
    "\n",
    "        link_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        button_div = link_soup.find('div', class_='product-phones__btn-title')\n",
    "\n",
    "        if button_div and button_div.text == 'Nömrəni göstər':\n",
    "            button_parent = button_div.find_parent('div', {'class': 'js-show-phones product-phones__btn'})\n",
    "            button_value = button_parent.find('div', class_='product-phones__btn-value')\n",
    "            if button_value:\n",
    "                phone_number = button_value['value'].strip()\n",
    "                data.append({'link': link, 'number': phone_number})\n",
    "            else:\n",
    "                button_parent.click()\n",
    "                time.sleep(1)\n",
    "                updated_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                phone_div = updated_soup.find('div', class_='product-phones__btn-value')\n",
    "                if phone_div:\n",
    "                    phone_number = phone_div['value'].strip()\n",
    "                    data.append({'link': link, 'number': phone_number})\n",
    "                else:\n",
    "                    data.append({'link': link, 'number': None})\n",
    "        else:\n",
    "            data.append({'link': link, 'number': None})\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760bbad7-3788-4bf7-a70f-7445b19c5edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')  # Run Chrome WebDriver in headless mode\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "data = []\n",
    "\n",
    "for page in range(1, 3):\n",
    "    url = f'https://bina.az/alqi-satqi?page={page}'\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    content = soup.find_all('div', class_='items-i')\n",
    "\n",
    "    for item in content:\n",
    "        link = 'https://bina.az' + item.a['href']\n",
    "\n",
    "        driver.get(link)\n",
    "        time.sleep(2)\n",
    "\n",
    "        link_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        button_div = link_soup.find('div', class_='product-phones__btn-title')\n",
    "\n",
    "        if button_div and button_div.text == 'Nömrəni göstər':\n",
    "            button_parent = button_div.find_parent('div', {'class': 'js-show-phones product-phones__btn'})\n",
    "            button_value = button_parent.find('div', class_='product-phones__btn-value')\n",
    "            if button_value:\n",
    "                phone_number = button_value.text.strip()\n",
    "                data.append({'link': link, 'number': phone_number})\n",
    "            else:\n",
    "                button_parent.click()\n",
    "                time.sleep(1)\n",
    "                updated_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                phone_div = updated_soup.find('div', class_='product-phones__btn-value')\n",
    "                if phone_div:\n",
    "                    phone_number = phone_div.text.strip()\n",
    "                    data.append({'link': link, 'number': phone_number})\n",
    "                else:\n",
    "                    data.append({'link': link, 'number': None})\n",
    "        else:\n",
    "            data.append({'link': link, 'number': None})\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a386fb-71df-40ed-a54f-598230bcc0c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
